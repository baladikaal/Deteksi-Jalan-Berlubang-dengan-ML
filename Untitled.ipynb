{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "import random,os,glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list = glob.glob(os.path.join(dir_path, '*/*.jpg'))\n",
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 662 images belonging to 3 classes.\n",
      "Found 72 images belonging to 3 classes.\n",
      "{'jalan_lubang': 0, 'jalan_retak': 1, 'jalan_tidak_rusak': 2}\n",
      "{0: 'jalan_lubang', 1: 'jalan_retak', 2: 'jalan_tidak_rusak'}\n"
     ]
    }
   ],
   "source": [
    "train=ImageDataGenerator(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         validation_split=0.1,\n",
    "                         rescale=1./255,\n",
    "                         shear_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,)\n",
    "\n",
    "test=ImageDataGenerator(rescale=1/255,\n",
    "                        validation_split=0.1)\n",
    "\n",
    "train_generator=train.flow_from_directory(dir_path,\n",
    "                                          target_size=(300,300),\n",
    "                                          batch_size=32,\n",
    "                                          class_mode='categorical',\n",
    "                                          subset='training')\n",
    "\n",
    "test_generator=test.flow_from_directory(dir_path,\n",
    "                                        target_size=(300,300),\n",
    "                                        batch_size=32,\n",
    "                                        class_mode='categorical',\n",
    "                                        subset='validation')\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "print(labels)\n",
    "\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 300, 300, 3), (32, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'jalan_lubang': 0, 'jalan_retak': 1, 'jalan_tidak_rusak': 2}\n"
     ]
    }
   ],
   "source": [
    "print (train_generator.class_indices)\n",
    "\n",
    "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "#Convolution blocks\n",
    "\n",
    "model.add(Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2)) \n",
    "#model.add(SpatialDropout2D(0.5)) # No accuracy\n",
    "\n",
    "model.add(Conv2D(64,(3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2)) \n",
    "#model.add(SpatialDropout2D(0.5))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2)) \n",
    "\n",
    "#Classification layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "#model.add(SpatialDropout2D(0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "filepath=\"model_2020_300.h5\"\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 75, 75, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2803776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,843,811\n",
      "Trainable params: 2,843,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc']) # RMS PROP - No accuracy\n",
    "\n",
    "#es=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2\n"
     ]
    }
   ],
   "source": [
    "BS = 32\n",
    "SPE= len(train_generator.classes)//BS\n",
    "VS = len(test_generator.classes)//BS\n",
    "print(SPE,VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-09ccae4dc935>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.1186 - acc: 0.4444\n",
      "Epoch 00001: val_acc improved from -inf to 0.40625, saving model to model_2020_300.h5\n",
      "20/20 [==============================] - 62s 3s/step - loss: 1.1186 - acc: 0.4444 - val_loss: 1.0962 - val_acc: 0.4062\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0831 - acc: 0.4540\n",
      "Epoch 00002: val_acc improved from 0.40625 to 0.46875, saving model to model_2020_300.h5\n",
      "20/20 [==============================] - 68s 3s/step - loss: 1.0831 - acc: 0.4540 - val_loss: 1.0481 - val_acc: 0.4688\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.9280 - acc: 0.4667\n",
      "Epoch 00003: val_acc did not improve from 0.46875\n",
      "20/20 [==============================] - 61s 3s/step - loss: 0.9280 - acc: 0.4667 - val_loss: 0.9544 - val_acc: 0.4531\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7947 - acc: 0.4587\n",
      "Epoch 00004: val_acc did not improve from 0.46875\n",
      "20/20 [==============================] - 71s 4s/step - loss: 0.7947 - acc: 0.4587 - val_loss: 0.7964 - val_acc: 0.4688\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.7363 - acc: 0.5286\n",
      "Epoch 00005: val_acc improved from 0.46875 to 0.64062, saving model to model_2020_300.h5\n",
      "20/20 [==============================] - 68s 3s/step - loss: 0.7363 - acc: 0.5286 - val_loss: 0.7071 - val_acc: 0.6406\n",
      "Epoch 6/100\n",
      " 2/20 [==>...........................] - ETA: 39s - loss: 0.7564 - acc: 0.6250"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=100,\n",
    "                              steps_per_epoch=SPE,\n",
    "                              validation_data=test_generator,\n",
    "                              validation_steps=VS,\n",
    "                              workers = 4,\n",
    "                              callbacks=callbacks_list) \n",
    "#41 epoch - 75% #73- 76.9%\n",
    "#78 epoch - 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
